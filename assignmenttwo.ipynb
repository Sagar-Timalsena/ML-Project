{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMk6Me8OYm5V53TDjhwgl5T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sagar-Timalsena/ML-Project/blob/master/assignmenttwo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q.n 1 Implement Backpropagation algorithm to train an ANN of configuration 2x2x1 to achieve XOR function. (Use sigmoid and Tanh activation function)\n"
      ],
      "metadata": {
        "id": "rNdJCNY9jnz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import library\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "LoBlVIw9jm6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sigmoid function\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))"
      ],
      "metadata": {
        "id": "Jmnd1Msgj6KO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#derivation of sigmoid function\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)"
      ],
      "metadata": {
        "id": "SHMIRvdekJ8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tanh function\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)"
      ],
      "metadata": {
        "id": "uSD2R6MOkbWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tanh activation function\n",
        "def tanh(x):\n",
        "    return np.tanh(x)"
      ],
      "metadata": {
        "id": "j4PnJPaYyUIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tanh derivation\n",
        "def tanh_derivative(x):\n",
        "    return 1 - np.square(x)"
      ],
      "metadata": {
        "id": "fcVKazepkiLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define forward propagation\n",
        "def forward_propagation(inputs, weights_input_hidden, weights_hidden_output):\n",
        "    hidden_inputs = np.dot(inputs, weights_input_hidden)\n",
        "    hidden_outputs = sigmoid(hidden_inputs)\n",
        "\n",
        "    final_inputs = np.dot(hidden_outputs, weights_hidden_output)\n",
        "    final_outputs = tanh(final_inputs)\n",
        "\n",
        "    return hidden_outputs, final_outputs"
      ],
      "metadata": {
        "id": "LHHXev3gkz3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define backpropagation\n",
        "def backpropagation(inputs, hidden_outputs, final_outputs, target, weights_hidden_output, weights_input_hidden, learning_rate):\n",
        "    output_errors = target - final_outputs\n",
        "    output_delta = output_errors * tanh_derivative(final_outputs)\n",
        "\n",
        "    hidden_errors = output_delta.dot(weights_hidden_output.T)\n",
        "    hidden_delta = hidden_errors * sigmoid_derivative(hidden_outputs)\n",
        "\n",
        "    weights_hidden_output += hidden_outputs.T.dot(output_delta) * learning_rate\n",
        "    weights_input_hidden += inputs.T.dot(hidden_delta) * learning_rate"
      ],
      "metadata": {
        "id": "zQYb5stbk4u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define XOR training data\n",
        "training_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "training_outputs = np.array([[0], [1], [1], [0]])"
      ],
      "metadata": {
        "id": "pMcVzgPsk_q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define network architecture\n",
        "input_size = 2\n",
        "hidden_size = 2\n",
        "output_size = 1"
      ],
      "metadata": {
        "id": "7S2gsLSslFCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights\n",
        "np.random.seed(1)\n",
        "weights_input_hidden = np.random.uniform(-1, 1, (input_size, hidden_size))\n",
        "weights_hidden_output = np.random.uniform(-1, 1, (hidden_size, output_size))"
      ],
      "metadata": {
        "id": "KHHMmXlflKMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set hyperparameters\n",
        "learning_rate = 0.1\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "pbQKfYzalOZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the network\n",
        "for epoch in range(num_epochs):\n",
        "    hidden_outputs, final_outputs = forward_propagation(training_inputs, weights_input_hidden, weights_hidden_output)\n",
        "    backpropagation(training_inputs, hidden_outputs, final_outputs, training_outputs, weights_hidden_output, weights_input_hidden, learning_rate)"
      ],
      "metadata": {
        "id": "Te6VDfg1lSY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE1psyuJ0HoJ"
      },
      "outputs": [],
      "source": [
        "# Test the network\n",
        "hidden_outputs, final_outputs = forward_propagation(training_inputs, weights_input_hidden, weights_hidden_output)\n",
        "print(\"Final outputs after training:\")\n",
        "print(final_outputs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q.n 2 Implement Backpropagation algorithm to train an ANN of configuration 3x2x2x1 to achieve majority function with 3-bit data. Output of the network must be 1 when there are two or more 1â€™s in the data. (Use sigmoid and Tanh activation function)"
      ],
      "metadata": {
        "id": "wqwIiGDUmk__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize the network\n",
        "input_size = 3\n",
        "hidden_size = 2\n",
        "output_size = 1\n"
      ],
      "metadata": {
        "id": "4QSZbdZ9mkSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights and biases randomly\n",
        "np.random.seed(1)\n",
        "hidden_weights = np.random.uniform(size=(input_size, hidden_size))\n",
        "hidden_bias = np.random.uniform(size=(1, hidden_size))\n",
        "output_weights = np.random.uniform(size=(hidden_size, output_size))\n",
        "output_bias = np.random.uniform(size=(1, output_size))\n"
      ],
      "metadata": {
        "id": "9Z1Emsj1xoUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data\n",
        "X = np.array([[0, 0, 0],\n",
        "              [0, 0, 1],\n",
        "              [0, 1, 0],\n",
        "              [0, 1, 1],\n",
        "              [1, 0, 0],\n",
        "              [1, 0, 1],\n",
        "              [1, 1, 0],\n",
        "              [1, 1, 1]])"
      ],
      "metadata": {
        "id": "TLUQGh-hxr3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target data\n",
        "y = np.array([[0], [0], [0], [1], [0], [1], [1], [1]])\n"
      ],
      "metadata": {
        "id": "1eaKrHUIxuea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "learning_rate = 0.1\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "f2cRvaHoxw02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    # Forward propagation\n",
        "    hidden_layer_input = np.dot(X, hidden_weights) + hidden_bias\n",
        "    hidden_layer_output = tanh(hidden_layer_input)\n",
        "    output_layer_input = np.dot(hidden_layer_output, output_weights) + output_bias\n",
        "    predicted_output = sigmoid(output_layer_input)\n",
        "\n",
        "    # Backpropagation\n",
        "    error = y - predicted_output\n",
        "    d_predicted_output = error * sigmoid_derivative(predicted_output)\n",
        "    error_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
        "    d_hidden_layer = error_hidden_layer * tanh_derivative(hidden_layer_output)\n",
        "\n",
        "    # Update weights and biases\n",
        "    output_weights += hidden_layer_output.T.dot(d_predicted_output) * learning_rate\n",
        "    output_bias += np.sum(d_predicted_output, axis=0, keepdims=True) * learning_rate\n",
        "    hidden_weights += X.T.dot(d_hidden_layer) * learning_rate\n",
        "    hidden_bias += np.sum(d_hidden_layer, axis=0, keepdims=True) * learning_rate\n",
        "\n"
      ],
      "metadata": {
        "id": "IUGRz3i_x0zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "hidden_layer_input = np.dot(X, hidden_weights) + hidden_bias\n",
        "hidden_layer_output = tanh(hidden_layer_input)\n",
        "output_layer_input = np.dot(hidden_layer_output, output_weights) + output_bias\n",
        "predicted_output = sigmoid(output_layer_input)\n",
        "\n",
        "print(\"Predicted Output:\")\n",
        "print(predicted_output)"
      ],
      "metadata": {
        "id": "KbIDj9O1yhoy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}